{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1GJLj5IsMNZvnOXnE9_JWhgDyZb2s1lHv","authorship_tag":"ABX9TyPQWe/rQXA+Wv8GGdl0Ag6S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-PfTXIGIci9S","executionInfo":{"status":"ok","timestamp":1763706604296,"user_tz":-330,"elapsed":971,"user":{"displayName":"Tanya Khanna","userId":"00787572321568557212"}},"outputId":"ecaa71b1-6529-48cc-e752-e2b47738f56b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Repo already exists.\n","\n","Pulling latest changes from User 1's main branch...\n","From https://github.com/Sanjana509/collaborative_cnn_team2\n"," * branch            main       -> FETCH_HEAD\n","Already up to date.\n","Current working directory: /content/collaborative_cnn_team2_USER2\n"]}],"source":["import os\n","import sys\n","import torch\n","import torch.nn as nn\n","import json\n","import importlib\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import accuracy_score, f1_score\n","import shutil\n","\n","YOUR_TOKEN = \"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\"\n","GIT_USERNAME = \"tanya1072\"\n","GIT_EMAIL = \"tanya1072@gmail.com\"\n","BASE_REPO_NAME = \"collaborative_cnn_team2\"\n","USER1_USERNAME = \"Sanjana509\"\n","\n","GIT_REPO_URL = f\"https://{GIT_USERNAME}:{YOUR_TOKEN}@github.com/{GIT_USERNAME}/{BASE_REPO_NAME}.git\"\n","REPO_PATH = f\"/content/{BASE_REPO_NAME}_USER2\"\n","\n","if not os.path.exists(REPO_PATH):\n","    print(f\"Cloning YOUR FORK: {GIT_USERNAME}/{BASE_REPO_NAME}...\")\n","    !git clone {GIT_REPO_URL} {REPO_PATH}\n","else:\n","    print(\"Repo already exists.\")\n","\n","os.chdir(REPO_PATH)\n","sys.path.insert(0, os.getcwd())\n","\n","!git config --global user.name \"{GIT_USERNAME}\"\n","!git config --global user.email \"{GIT_EMAIL}\"\n","!git remote add upstream https://github.com/{USER1_USERNAME}/{BASE_REPO_NAME}.git 2>/dev/null\n","print(\"\\nPulling latest changes from User 1's main branch...\")\n","!git pull upstream main\n","\n","print(f\"Current working directory: {os.getcwd()}\")"]},{"cell_type":"code","source":["import os\n","from google.colab import files\n","uploaded = files.upload()\n","\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition\n","!unzip -q dogs-vs-cats-redux-kernels-edition.zip\n","\n","!unzip -q train.zip -d dataset_user2\n","user2_data_dir = \"dataset_user2/train\"\n","\n","\n","print(\"Organizing dataset...\")\n","base_dir = user2_data_dir\n","cat_dir = os.path.join(base_dir, 'cat')\n","dog_dir = os.path.join(base_dir, 'dog')\n","os.makedirs(cat_dir, exist_ok=True)\n","os.makedirs(dog_dir, exist_ok=True)\n","\n","\n","for file_name in os.listdir(base_dir):\n","    src = os.path.join(base_dir, file_name)\n","    if os.path.isfile(src):\n","        if file_name.startswith('cat.'):\n","            shutil.move(src, cat_dir)\n","        elif file_name.startswith('dog.'):\n","            shutil.move(src, dog_dir)\n","print(f\"Dataset organized at: {user2_data_dir}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"qo6L6QBQcrPX","executionInfo":{"status":"error","timestamp":1763706679763,"user_tz":-330,"elapsed":73016,"user":{"displayName":"Tanya Khanna","userId":"00787572321568557212"}},"outputId":"f0525ec8-d29c-4f21-8178-fa99c14772ee"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-2b5639b1-37ad-46e4-b5d8-49f03352a445\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-2b5639b1-37ad-46e4-b5d8-49f03352a445\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle (1).json\n","dogs-vs-cats-redux-kernels-edition.zip: Skipping, found more recently modified local copy (use --force to force download)\n","replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: Organizing dataset...\n"]},{"output_type":"error","ename":"Error","evalue":"Destination path 'dataset_user2/train/cat/cat.5519.jpg' already exists","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1509895908.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dog.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Destination path '%s' already exists\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mError\u001b[0m: Destination path 'dataset_user2/train/cat/cat.5519.jpg' already exists"]}]},{"cell_type":"code","source":["import os\n","import sys\n","import json\n","import torch\n","import torch.nn as nn\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import importlib\n","\n","print(\"Connecting to User 1's repository...\")\n","USER1_BASE_REPO = \"collaborative_cnn_team2\"\n","USER1_USERNAME = \"Sanjana509\"\n","!git remote add upstream https://github.com/{USER1_USERNAME}/{USER1_BASE_REPO}.git 2>/dev/null\n","!git remote set-url upstream https://github.com/{USER1_USERNAME}/{USER1_BASE_REPO}.git\n","!git fetch upstream\n","\n","print(\"Attempting to pull Model V1 files from User 1's repository...\")\n","!git checkout upstream/main -- models/ results/\n","\n","\n","if os.path.exists(\"models/model_v1.py\"):\n","    print(\"found 'models/model_v1.py' and 'models/model_v1.pth'\")\n","\n","\n","    if os.getcwd() not in sys.path:\n","        sys.path.insert(0, os.getcwd())\n","        print(\"added current directory to system path for module imports.\")\n","\n","    if not os.path.exists('models/__init__.py'):\n","        !touch models/__init__.py\n","        print(\"Created models/__init__.py for successful Python import.\")\n","\n","else:\n","    print(\"Not found 'models/model_v1.py'. Please confirm User 1 has merged their PR or run: !git checkout upstream/dev_user1 -- models/ results/\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7wtikpHIc2qJ","executionInfo":{"status":"ok","timestamp":1763706683530,"user_tz":-330,"elapsed":920,"user":{"displayName":"Tanya Khanna","userId":"00787572321568557212"}},"outputId":"955aac05-b1f4-4346-e5cb-20abd3cee322"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Connecting to User 1's repository...\n","Attempting to pull Model V1 files from User 1's repository...\n","found 'models/model_v1.py' and 'models/model_v1.pth'\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models, datasets, transforms\n","from torch.utils.data import DataLoader\n","import json\n","import os\n","import sys\n","import importlib\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","possible_dirs = [\"dataset_user2/train\", \"train\", \"dummy_data\"]\n","data_dir = next((d for d in possible_dirs if os.path.exists(d)), \"dataset_user2/train\")\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","try:\n","    train_dataset = datasets.ImageFolder(data_dir, transform=transform)\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","    print(f\"Training data loaded from: {data_dir}\")\n","except Exception as e:\n","    print(f\"Data load error: {e}. Creating dummy data to allow code to run.\")\n","    os.makedirs(f\"{data_dir}/cats\", exist_ok=True)\n","    os.makedirs(f\"{data_dir}/dogs\", exist_ok=True)\n","    train_loader = DataLoader(datasets.ImageFolder(data_dir, transform=transform), batch_size=2)\n","\n","model_v2_code = \"\"\"\n","import torch\n","import torch.nn as nn\n","from torchvision import models\n","\n","class ModelV2(nn.Module):\n","    def __init__(self):\n","        super(ModelV2, self).__init__()\n","        self.model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n","\n","        for param in self.model.features.parameters():\n","            param.requires_grad = False\n","\n","        # IMPROVEMENT: Dropout + Linear Head\n","        in_features = self.model.classifier[1].in_features\n","        self.model.classifier = nn.Sequential(\n","            nn.Dropout(p=0.3),\n","            nn.Linear(in_features, 2)\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\"\"\"\n","if not os.path.exists('models'): os.makedirs('models')\n","with open('models/model_v2.py', 'w') as f:\n","    f.write(model_v2_code)\n","\n","#initialize and train\n","import models.model_v2\n","importlib.reload(models.model_v2)\n","from models.model_v2 import ModelV2\n","\n","model_v2 = ModelV2().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_v2.parameters(), lr=0.001)\n","\n","num_epochs = 15\n","print(f\"starting training (Model V2) for {num_epochs} epochs...\")\n","\n","for epoch in range(num_epochs):\n","    model_v2.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for i, (inputs, labels) in enumerate(train_loader):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model_v2(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        running_loss += loss.item()\n","\n","    epoch_loss = running_loss / (i + 1)\n","    epoch_acc = 100 * correct / total\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n","\n","torch.save(model_v2.state_dict(), 'models/model_v2.pth')\n","metrics_v2 = {\n","    \"model\": \"model_v2\",\n","    \"dataset\": \"Dogs vs Cats Redux (User 2)\",\n","    \"accuracy\": epoch_acc,\n","    \"epochs\": num_epochs,\n","    \"improvements\": \"Added Dropout (p=0.3)\"\n","}\n","if not os.path.exists('results'): os.makedirs('results')\n","with open('results/metrics_v2.json', 'w') as f:\n","    json.dump(metrics_v2, f, indent=4)\n","print(\"Model and metrics saved.\")"],"metadata":{"id":"K5YQz1ZTc6MZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#push to GitHub\n","!git checkout -B dev_user2\n","print(\"switched dev_user2 branch.\")\n","!git add results/tarin_v2_user2.json\n","!git commit -m \"tarin added\"\n","!git push -u origin dev_user2\n","\n","print(\"=\"*50)\n","print(\"push to github.\")\n","print(\"=\"*50)"],"metadata":{"id":"JjZPX23zxccf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git pull origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xlpPLKvhsGUB","executionInfo":{"status":"ok","timestamp":1763706576193,"user_tz":-330,"elapsed":603,"user":{"displayName":"Tanya Khanna","userId":"00787572321568557212"}},"outputId":"7db40b85-83ac-4b67-c5d4-d455920dfec5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["From https://github.com/tanya1072/collaborative_cnn_team2\n"," * branch            main       -> FETCH_HEAD\n","Already up to date.\n"]}]},{"cell_type":"code","source":["!git checkout -b dev_user2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qm5-AX3dsKDT","executionInfo":{"status":"ok","timestamp":1763706577029,"user_tz":-330,"elapsed":105,"user":{"displayName":"Tanya Khanna","userId":"00787572321568557212"}},"outputId":"ecc6ac5c-dcf3-433d-9a26-cafbcd82c3bb"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: A branch named 'dev_user2' already exists.\n"]}]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uTDvF8CYsMvx","executionInfo":{"status":"ok","timestamp":1763706578147,"user_tz":-330,"elapsed":84,"user":{"displayName":"Tanya Khanna","userId":"00787572321568557212"}},"outputId":"56cc3ac1-f5da-4e96-c4fb-b656f84db8d2"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/collaborative_cnn_team2_USER2\n"]}]},{"cell_type":"code","source":["!ls -F notebooks/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bnDhUkaasPho","executionInfo":{"status":"ok","timestamp":1763706581088,"user_tz":-330,"elapsed":136,"user":{"displayName":"Tanya Khanna","userId":"00787572321568557212"}},"outputId":"ed514669-2728-4411-e2a7-1df794791f57"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["test_v1.ipynb  train_v1.ipynb  train_v2.ipynb\n"]}]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/Colab Notebooks/train_v2.ipynb\" notebooks/"],"metadata":{"id":"uZ8E9vLIsStz","executionInfo":{"status":"ok","timestamp":1763706583543,"user_tz":-330,"elapsed":799,"user":{"displayName":"Tanya Khanna","userId":"00787572321568557212"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["!git add notebooks/train_v2.ipynb"],"metadata":{"id":"qsK6vu-5sWwZ","executionInfo":{"status":"ok","timestamp":1763706586028,"user_tz":-330,"elapsed":93,"user":{"displayName":"Tanya Khanna","userId":"00787572321568557212"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"Add train_v2\"\n","\n","!git push origin dev_user2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pKRw6ofhsbQO","executionInfo":{"status":"ok","timestamp":1763706589288,"user_tz":-330,"elapsed":816,"user":{"displayName":"Tanya Khanna","userId":"00787572321568557212"}},"outputId":"346f17a3-a35e-4dc0-bf28-3a5def7d1a0d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[dev_user2 2315eaf] Add train_v2\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n","remote: Invalid username or token. Password authentication is not supported for Git operations.\n","fatal: Authentication failed for 'https://github.com/tanya1072/collaborative_cnn_team2.git/'\n"]}]}]}