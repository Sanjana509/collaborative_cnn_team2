{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1GJLj5IsMNZvnOXnE9_JWhgDyZb2s1lHv","authorship_tag":"ABX9TyOUN2Y03Sv7B6jiPAvm/JrF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-PfTXIGIci9S","executionInfo":{"status":"ok","timestamp":1763706353994,"user_tz":-330,"elapsed":3252,"user":{"displayName":"Tanya Khanna","userId":"00787572321568557212"}},"outputId":"92d8c474-f210-4b21-dc04-730aaa03e16a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning YOUR FORK: tanya1072/collaborative_cnn_team2...\n","Cloning into '/content/collaborative_cnn_team2_USER2'...\n","remote: Enumerating objects: 77, done.\u001b[K\n","remote: Counting objects: 100% (14/14), done.\u001b[K\n","remote: Compressing objects: 100% (12/12), done.\u001b[K\n","remote: Total 77 (delta 1), reused 7 (delta 1), pack-reused 63 (from 1)\u001b[K\n","Receiving objects: 100% (77/77), 8.64 MiB | 17.58 MiB/s, done.\n","Resolving deltas: 100% (31/31), done.\n","\n","Pulling latest changes from User 1's main branch...\n","remote: Enumerating objects: 1, done.\u001b[K\n","remote: Counting objects: 100% (1/1), done.\u001b[K\n","remote: Total 1 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Unpacking objects: 100% (1/1), 905 bytes | 905.00 KiB/s, done.\n","From https://github.com/Sanjana509/collaborative_cnn_team2\n"," * branch            main       -> FETCH_HEAD\n"," * [new branch]      main       -> upstream/main\n","Updating 6a7c942..4603706\n","Fast-forward\n"," models/model_v1.pth      | Bin \u001b[31m9153931\u001b[m -> \u001b[32m9153931\u001b[m bytes\n"," models/model_v1.py       |   4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n"," notebooks/test_v1.ipynb  |   1 \u001b[32m+\u001b[m\n"," notebooks/train_v1.ipynb |   1 \u001b[32m+\u001b[m\n"," results/metrics_v1.json  |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n"," 5 files changed, 5 insertions(+), 3 deletions(-)\n"," create mode 100644 notebooks/test_v1.ipynb\n"," create mode 100644 notebooks/train_v1.ipynb\n","Current working directory: /content/collaborative_cnn_team2_USER2\n"]}],"source":["import os\n","import sys\n","import torch\n","import torch.nn as nn\n","import json\n","import importlib\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import accuracy_score, f1_score\n","import shutil\n","\n","YOUR_TOKEN = \"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\"\n","GIT_USERNAME = \"tanya1072\"\n","GIT_EMAIL = \"tanya1072@gmail.com\"\n","BASE_REPO_NAME = \"collaborative_cnn_team2\"\n","USER1_USERNAME = \"Sanjana509\"\n","\n","GIT_REPO_URL = f\"https://{GIT_USERNAME}:{YOUR_TOKEN}@github.com/{GIT_USERNAME}/{BASE_REPO_NAME}.git\"\n","REPO_PATH = f\"/content/{BASE_REPO_NAME}_USER2\"\n","\n","if not os.path.exists(REPO_PATH):\n","    print(f\"Cloning YOUR FORK: {GIT_USERNAME}/{BASE_REPO_NAME}...\")\n","    !git clone {GIT_REPO_URL} {REPO_PATH}\n","else:\n","    print(\"Repo already exists.\")\n","\n","os.chdir(REPO_PATH)\n","sys.path.insert(0, os.getcwd())\n","\n","!git config --global user.name \"{GIT_USERNAME}\"\n","!git config --global user.email \"{GIT_EMAIL}\"\n","!git remote add upstream https://github.com/{USER1_USERNAME}/{BASE_REPO_NAME}.git 2>/dev/null\n","print(\"\\nPulling latest changes from User 1's main branch...\")\n","!git pull upstream main\n","\n","print(f\"Current working directory: {os.getcwd()}\")"]},{"cell_type":"code","source":["import os\n","from google.colab import files\n","uploaded = files.upload()\n","\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition\n","!unzip -q dogs-vs-cats-redux-kernels-edition.zip\n","\n","!unzip -q train.zip -d dataset_user2\n","user2_data_dir = \"dataset_user2/train\"\n","\n","\n","print(\"Organizing dataset...\")\n","base_dir = user2_data_dir\n","cat_dir = os.path.join(base_dir, 'cat')\n","dog_dir = os.path.join(base_dir, 'dog')\n","os.makedirs(cat_dir, exist_ok=True)\n","os.makedirs(dog_dir, exist_ok=True)\n","\n","\n","for file_name in os.listdir(base_dir):\n","    src = os.path.join(base_dir, file_name)\n","    if os.path.isfile(src):\n","        if file_name.startswith('cat.'):\n","            shutil.move(src, cat_dir)\n","        elif file_name.startswith('dog.'):\n","            shutil.move(src, dog_dir)\n","print(f\"Dataset organized at: {user2_data_dir}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":160},"id":"qo6L6QBQcrPX","executionInfo":{"status":"ok","timestamp":1763706448859,"user_tz":-330,"elapsed":68066,"user":{"displayName":"Tanya Khanna","userId":"00787572321568557212"}},"outputId":"07094a37-a5af-47ef-e397-a4ec218dd6ae"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-f9c16172-6a40-47dc-8b3e-4fcfb32df82c\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f9c16172-6a40-47dc-8b3e-4fcfb32df82c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n","Downloading dogs-vs-cats-redux-kernels-edition.zip to /content/collaborative_cnn_team2_USER2\n"," 91% 740M/814M [00:04<00:01, 41.9MB/s]\n","100% 814M/814M [00:04<00:00, 204MB/s] \n","Organizing dataset...\n","Dataset organized at: dataset_user2/train\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","import json\n","import torch\n","import torch.nn as nn\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import importlib\n","\n","print(\"Connecting to User 1's repository...\")\n","USER1_BASE_REPO = \"collaborative_cnn_team2\"\n","USER1_USERNAME = \"Sanjana509\"\n","!git remote add upstream https://github.com/{USER1_USERNAME}/{USER1_BASE_REPO}.git 2>/dev/null\n","!git remote set-url upstream https://github.com/{USER1_USERNAME}/{USER1_BASE_REPO}.git\n","!git fetch upstream\n","\n","print(\"Attempting to pull Model V1 files from User 1's repository...\")\n","!git checkout upstream/main -- models/ results/\n","\n","\n","if os.path.exists(\"models/model_v1.py\"):\n","    print(\"found 'models/model_v1.py' and 'models/model_v1.pth'\")\n","\n","\n","    if os.getcwd() not in sys.path:\n","        sys.path.insert(0, os.getcwd())\n","        print(\"added current directory to system path for module imports.\")\n","\n","    if not os.path.exists('models/__init__.py'):\n","        !touch models/__init__.py\n","        print(\"Created models/__init__.py for successful Python import.\")\n","\n","else:\n","    print(\"Not found 'models/model_v1.py'. Please confirm User 1 has merged their PR or run: !git checkout upstream/dev_user1 -- models/ results/\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7wtikpHIc2qJ","executionInfo":{"status":"ok","timestamp":1763706449890,"user_tz":-330,"elapsed":1017,"user":{"displayName":"Tanya Khanna","userId":"00787572321568557212"}},"outputId":"2698123a-5d24-444f-913d-7f6781b2679e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Connecting to User 1's repository...\n","From https://github.com/Sanjana509/collaborative_cnn_team2\n"," * [new branch]      dev_user1  -> upstream/dev_user1\n","Attempting to pull Model V1 files from User 1's repository...\n","found 'models/model_v1.py' and 'models/model_v1.pth'\n","Created models/__init__.py for successful Python import.\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models, datasets, transforms\n","from torch.utils.data import DataLoader\n","import json\n","import os\n","import sys\n","import importlib\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","possible_dirs = [\"dataset_user2/train\", \"train\", \"dummy_data\"]\n","data_dir = next((d for d in possible_dirs if os.path.exists(d)), \"dataset_user2/train\")\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","try:\n","    train_dataset = datasets.ImageFolder(data_dir, transform=transform)\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","    print(f\"Training data loaded from: {data_dir}\")\n","except Exception as e:\n","    print(f\"Data load error: {e}. Creating dummy data to allow code to run.\")\n","    os.makedirs(f\"{data_dir}/cats\", exist_ok=True)\n","    os.makedirs(f\"{data_dir}/dogs\", exist_ok=True)\n","    train_loader = DataLoader(datasets.ImageFolder(data_dir, transform=transform), batch_size=2)\n","\n","model_v2_code = \"\"\"\n","import torch\n","import torch.nn as nn\n","from torchvision import models\n","\n","class ModelV2(nn.Module):\n","    def __init__(self):\n","        super(ModelV2, self).__init__()\n","        self.model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n","\n","        for param in self.model.features.parameters():\n","            param.requires_grad = False\n","\n","        # IMPROVEMENT: Dropout + Linear Head\n","        in_features = self.model.classifier[1].in_features\n","        self.model.classifier = nn.Sequential(\n","            nn.Dropout(p=0.3),\n","            nn.Linear(in_features, 2)\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\"\"\"\n","if not os.path.exists('models'): os.makedirs('models')\n","with open('models/model_v2.py', 'w') as f:\n","    f.write(model_v2_code)\n","\n","#initialize and train\n","import models.model_v2\n","importlib.reload(models.model_v2)\n","from models.model_v2 import ModelV2\n","\n","model_v2 = ModelV2().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_v2.parameters(), lr=0.001)\n","\n","num_epochs = 15\n","print(f\"starting training (Model V2) for {num_epochs} epochs...\")\n","\n","for epoch in range(num_epochs):\n","    model_v2.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for i, (inputs, labels) in enumerate(train_loader):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model_v2(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        running_loss += loss.item()\n","\n","    epoch_loss = running_loss / (i + 1)\n","    epoch_acc = 100 * correct / total\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n","\n","torch.save(model_v2.state_dict(), 'models/model_v2.pth')\n","metrics_v2 = {\n","    \"model\": \"model_v2\",\n","    \"dataset\": \"Dogs vs Cats Redux (User 2)\",\n","    \"accuracy\": epoch_acc,\n","    \"epochs\": num_epochs,\n","    \"improvements\": \"Added Dropout (p=0.3)\"\n","}\n","if not os.path.exists('results'): os.makedirs('results')\n","with open('results/metrics_v2.json', 'w') as f:\n","    json.dump(metrics_v2, f, indent=4)\n","print(\"Model and metrics saved.\")"],"metadata":{"id":"K5YQz1ZTc6MZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#push to GitHub\n","!git checkout -B dev_user2\n","print(\"switched dev_user2 branch.\")\n","!git add results/tarin_v2_user2.json\n","!git commit -m \"tarin added\"\n","!git push -u origin dev_user2\n","\n","print(\"=\"*50)\n","print(\"push to github.\")\n","print(\"=\"*50)"],"metadata":{"id":"JjZPX23zxccf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git pull origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xlpPLKvhsGUB","executionInfo":{"status":"ok","timestamp":1763706460972,"user_tz":-330,"elapsed":610,"user":{"displayName":"Tanya Khanna","userId":"00787572321568557212"}},"outputId":"91f4251a-3001-4ac1-a3c5-d78bffffdb38"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["From https://github.com/tanya1072/collaborative_cnn_team2\n"," * branch            main       -> FETCH_HEAD\n","Already up to date.\n"]}]},{"cell_type":"code","source":["!git checkout -b dev_user2"],"metadata":{"id":"Qm5-AX3dsKDT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"uTDvF8CYsMvx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls -F notebooks/"],"metadata":{"id":"bnDhUkaasPho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/Colab Notebooks/train_v2.ipynb\" notebooks/"],"metadata":{"id":"uZ8E9vLIsStz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add notebooks/train_v2.ipynb"],"metadata":{"id":"qsK6vu-5sWwZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"Add train_v2\"\n","\n","!git push origin dev_user2"],"metadata":{"id":"pKRw6ofhsbQO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zzYCZKxmyvxQ"},"execution_count":null,"outputs":[]}]}